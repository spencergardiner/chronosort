{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "05593346",
            "metadata": {},
            "source": [
                "<a href=\"https://colab.research.google.com/github/dellacortelab/chronosort/blob/main/chronosort_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> "
            ]
        },
        {
            "cell_type": "markdown",
            "id": "22a4f9be",
            "metadata": {},
            "source": [
                "# **Chronosort Colab Pipeline**\n",
                "Run the Chronosort PCA workflow directly in Google Colab using uploaded MMCIF structures.\n",
                "\n",
                "**Workflow overview**\n",
                "- Install dependencies and fetch the Chronosort source code\n",
                "- Upload MMCIF files (optionally bundled inside .zip or .tar archives)\n",
                "- Configure PCA parameters and execute the pipeline\n",
                "- Download the resulting trajectory, eigenvectors, projections, and plots\n",
                "\n",
                "**Tips**\n",
                "- Each code cell can be run with the â–¶ button on the left.\n",
                "- Uploads are placed in a scratch directory for the current Colab session only.\n",
                "- If you re-run the upload cell, previously uploaded data will be replaced.\n",
                "- Larger uploads may take a few minutes to transfer; keep the browser tab open until the upload finishes.\n",
                "\n",
                "**Colab notes**\n",
                "- Runtime: GPU is optional for this workflow, but the notebook retains Colab's default GPU metadata.\n",
                "- Session storage is ephemeral; download results before ending the session."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0a045398",
            "metadata": {
                "cellView": "form",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "%%time\n",
                "#@title Install dependencies and fetch Chronosort\n",
                "#@markdown This cell clones the Chronosort repository and installs the required Python packages.\n",
                "import sys\n",
                "import subprocess\n",
                "from pathlib import Path\n",
                "\n",
                "repo_url = \"https://github.com/dellacortelab/chronosort.git\"\n",
                "repo_path = Path(\"chronosort\")\n",
                "if not repo_path.exists():\n",
                "    subprocess.run([\"git\", \"clone\", \"--depth\", \"1\", repo_url, str(repo_path)], check=True)\n",
                "requirements_path = repo_path / \"requirements.txt\"\n",
                "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"-r\", str(requirements_path)], check=True)\n",
                "print(\"Chronosort repository ready.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a2a30c46",
            "metadata": {
                "cellView": "form",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "#@title Upload CIF files or archives\n",
                "#@markdown Upload one or more `.cif` files, or archives (`.zip`, `.tar`, `.tar.gz`, `.tgz`, `.tar.bz2`) containing them.\n",
                "from pathlib import Path\n",
                "import io\n",
                "import zipfile\n",
                "import tarfile\n",
                "import shutil\n",
                "\n",
                "try:\n",
                "    from google.colab import files\n",
                "except ImportError as exc:\n",
                "    raise RuntimeError(\"This cell is intended to run inside Google Colab.\") from exc\n",
                "\n",
                "upload_root = Path(\"user_uploads\")\n",
                "cif_dir = upload_root / \"cif_inputs\"\n",
                "if cif_dir.exists():\n",
                "    shutil.rmtree(cif_dir)\n",
                "cif_dir.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "def _unique_target(directory, filename):\n",
                "    base_path = Path(filename).name\n",
                "    stem = Path(base_path).stem\n",
                "    suffix = Path(base_path).suffix\n",
                "    candidate = directory / base_path\n",
                "    counter = 1\n",
                "    while candidate.exists():\n",
                "        candidate = directory / f\"{stem}_{counter}{suffix}\"\n",
                "        counter += 1\n",
                "    return candidate\n",
                "\n",
                "def _should_skip(filename: str) -> bool:\n",
                "    base = Path(filename).name\n",
                "    return base.startswith(\"._\") or base.startswith(\"__MACOSX\")\n",
                "\n",
                "uploaded = files.upload()\n",
                "if not uploaded:\n",
                "    raise RuntimeError(\"No files were uploaded. Please provide at least one CIF or archive.\")\n",
                "\n",
                "for name, data in uploaded.items():\n",
                "    if _should_skip(name):\n",
                "        print(f\"Skipped hidden file: {name}\")\n",
                "        continue\n",
                "    file_path = upload_root / name\n",
                "    file_path.write_bytes(data)\n",
                "    lower_name = name.lower()\n",
                "    if lower_name.endswith(\".zip\"):\n",
                "        with zipfile.ZipFile(io.BytesIO(data)) as zf:\n",
                "            for member in zf.namelist():\n",
                "                if member.endswith(\"/\") or _should_skip(member):\n",
                "                    continue\n",
                "                if member.lower().endswith(\".cif\"):\n",
                "                    target = _unique_target(cif_dir, member)\n",
                "                    with zf.open(member) as source, open(target, \"wb\") as dest:\n",
                "                        dest.write(source.read())\n",
                "    elif lower_name.endswith((\".tar\", \".tar.gz\", \".tgz\", \".tar.bz2\")):\n",
                "        with tarfile.open(fileobj=io.BytesIO(data)) as tf:\n",
                "            for member in tf.getmembers():\n",
                "                if not member.isfile() or _should_skip(member.name):\n",
                "                    continue\n",
                "                if member.name.lower().endswith(\".cif\"):\n",
                "                    target = _unique_target(cif_dir, member.name)\n",
                "                    with tf.extractfile(member) as source, open(target, \"wb\") as dest:\n",
                "                        dest.write(source.read())\n",
                "    elif lower_name.endswith(\".cif\"):\n",
                "        target = _unique_target(cif_dir, name)\n",
                "        shutil.copy2(file_path, target)\n",
                "    else:\n",
                "        print(f\"Skipped unsupported file: {name}\")\n",
                "\n",
                "cif_files = [p for p in sorted(cif_dir.glob(\"*.cif\")) if not p.name.startswith(\"._\")]\n",
                "if not cif_files:\n",
                "    raise RuntimeError(\"No CIF files found after processing uploads.\")\n",
                "CIF_INPUT_DIR = str(cif_dir.resolve())\n",
                "print(f\"Added {len(cif_files)} CIF files to {CIF_INPUT_DIR}\")\n",
                "for sample in cif_files[:5]:\n",
                "    print(\" -\", sample.name)\n",
                "if len(cif_files) > 5:\n",
                "    print(f\"... and {len(cif_files) - 5} more\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "93c49ec8",
            "metadata": {
                "cellView": "form",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "%%time\n",
                "#@title Run Chronosort PCA pipeline\n",
                "#@markdown Configure paths and parameters, then launch the Chronosort analysis.\n",
                "import sys\n",
                "import subprocess\n",
                "from pathlib import Path\n",
                "\n",
                "if \"CIF_INPUT_DIR\" not in globals():\n",
                "    raise RuntimeError(\"No CIF input directory detected. Please run the upload cell first.\")\n",
                "\n",
                "cif_dir_override = \"\"  # @param {type:\"string\"}\n",
                "scale = 30.0  # @param {type:\"number\"}\n",
                "components_text = \"0\"  # @param {type:\"string\"}\n",
                "# components_text accepts 0-based PCA indices (e.g., \"0 1\") to choose which eigenvectors drive the projection\n",
                "trajectory_filename = \"trajectory.pdb\"  # @param {type:\"string\"}\n",
                "vecs_filename = \"vecs.txt\"  # @param {type:\"string\"}\n",
                "projection_filename = \"projection.pdb\"  # @param {type:\"string\"}\n",
                "\n",
                "cif_dir_path = Path(cif_dir_override.strip()) if cif_dir_override.strip() else Path(CIF_INPUT_DIR)\n",
                "if not cif_dir_path.exists():\n",
                "    raise FileNotFoundError(f\"cif_dir '{cif_dir_path}' does not exist.\")\n",
                "\n",
                "components = []\n",
                "for piece in components_text.replace(\";\", \",\").split(\",\"):\n",
                "    piece = piece.strip()\n",
                "    if piece:\n",
                "        components.append(int(piece))\n",
                "if not components:\n",
                "    components = [0]\n",
                "\n",
                "output_root = Path(\"chronosort_outputs\")\n",
                "output_root.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "trajectory_path = output_root / trajectory_filename\n",
                "vecs_path = output_root / vecs_filename\n",
                "projection_path = output_root / projection_filename\n",
                "\n",
                "repo_root = Path(\"chronosort\")\n",
                "cmd = [\n",
                "    sys.executable,\n",
                "    \"scripts/run_analysis.py\",\n",
                "    \"--cif_dir\",\n",
                "    str(cif_dir_path),\n",
                "    \"--trajectory_file\",\n",
                "    str(trajectory_path.resolve()),\n",
                "    \"--vecs_file\",\n",
                "    str(vecs_path.resolve()),\n",
                "    \"--projection_file\",\n",
                "    str(projection_path.resolve()),\n",
                "    \"--scale\",\n",
                "    str(scale),\n",
                "    \"--components\",\n",
                "]\n",
                "cmd.extend(str(c) for c in components)\n",
                "\n",
                "print(\"Running (cwd=chronosort):\", \" \".join(cmd))\n",
                "result = subprocess.run(cmd, cwd=repo_root, text=True, capture_output=True)\n",
                "if result.stdout:\n",
                "    print(result.stdout)\n",
                "if result.returncode != 0:\n",
                "    if result.stderr:\n",
                "        print(\"stderr:\\n\" + result.stderr)\n",
                "    raise RuntimeError(f\"Chronosort pipeline failed with exit code {result.returncode}.\")\n",
                "\n",
                "eigenvalues_path = repo_root / \"output\" / \"eigenvalues.png\"\n",
                "if eigenvalues_path.exists():\n",
                "    target = output_root / \"eigenvalues.png\"\n",
                "    target.write_bytes(eigenvalues_path.read_bytes())\n",
                "    print(f\"Copied eigenvalue plot to {target}\")\n",
                "\n",
                "print(\"\\nGenerated files:\")\n",
                "for path in sorted(output_root.glob(\"*\")):\n",
                "    print(\" -\", path)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "88f99935",
            "metadata": {
                "cellView": "form",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "%%time\n",
                "#@title Download results archive\n",
                "#@markdown Package the generated outputs into a zip archive and download them locally.\n",
                "from pathlib import Path\n",
                "import shutil\n",
                "import datetime\n",
                "\n",
                "try:\n",
                "    from google.colab import files\n",
                "except ImportError as exc:\n",
                "    raise RuntimeError(\"This cell is intended to run inside Google Colab.\") from exc\n",
                "\n",
                "output_root = Path(\"chronosort_outputs\")\n",
                "if not output_root.exists():\n",
                "    raise RuntimeError(\"No outputs found. Run the analysis before downloading.\")\n",
                "\n",
                "timestamp = datetime.datetime.now(datetime.UTC).strftime(\"%Y%m%d_%H%M%S\")\n",
                "archive_name = f\"chronosort_results_{timestamp}\"\n",
                "archive_path = shutil.make_archive(archive_name, \"zip\", root_dir=output_root)\n",
                "print(f\"Created archive: {archive_path}\")\n",
                "files.download(archive_path)"
            ]
        }
    ],
    "metadata": {
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
